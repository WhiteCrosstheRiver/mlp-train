# 配置系统

mlp-train 使用 `Config` 类来管理全局配置参数。本章节详细介绍如何配置和使用这些参数。

## Config 类概述

`Config` 是一个单例类，包含所有默认配置参数：

```python
import mlptrain as mlt

# 访问配置
print(mlt.Config.n_cores)
```

## 基本配置

### 并行计算核心数

```python
mlt.Config.n_cores = 10  # 使用 10 个核心
```

**注意**：在主动学习中，`n_cores` 必须是 `n_configs_iter` 的倍数。

### 量子化学方法配置

#### ORCA 配置

```python
mlt.Config.orca_keywords = ['PBE', 'def2-SVP', 'EnGrad']
```

常用关键词组合：
- **PBE/def2-SVP**：快速 DFT 计算
- **PBE0/def2-TZVP**：更精确但更慢
- **B3LYP/6-31G(d)**：常用混合泛函

#### Gaussian 配置

```python
mlt.Config.gaussian_keywords = [
    'PBEPBE',
    'Def2SVP',
    'Force(NoStep)',
    'integral=ultrafinegrid'
]
```

## 模型特定配置

### GAP 参数

```python
# GAP 默认参数
mlt.Config.gap_default_params = {
    'sigma_E': 10**(-4.0),  # 能量噪声（eV）
    'sigma_F': 10**(-2.0),  # 力噪声（eV Å⁻¹）
}

# GAP SOAP 参数
mlt.Config.gap_default_soap_params = {
    'cutoff': 4.0,      # 截断半径（Å）
    'n_sparse': 1000,   # 稀疏点数量
    'l_max': 6,         # 角动量量子数（n_max = 2*l_max）
    'sigma_at': 0.5,    # 原子宽度（Å）
}
```

### ACE 参数

```python
mlt.Config.ace_params = {
    'N': 4,              # 最大相关阶数
    'r_cut': 4.0,       # 外截断半径（Å）
    'deg_pair': 5,      # 对势阶数
    'r_cut_pair': 5.0,  # 对势截断半径（Å）
}
```

### MACE 参数

```python
mlt.Config.mace_params = {
    'valid_fraction': 0.1,           # 验证集比例
    'max_num_epochs': 1200,          # 最大训练轮数
    'config_type_weights': '{"Default":1.0}',
    'model': 'MACE',
    'loss': 'weighted',
    'energy_weight': 1.0,            # 能量权重
    'forces_weight': 5.0,            # 力权重
    'hidden_irreps': '128x0e + 128x1o',
    'batch_size': 10,
    'r_max': 5.0,                    # 截断半径（Å）
    'correlation': 3,
    'device': 'cuda',                 # 'cuda' 或 'cpu'
    'calc_device': 'cpu',
    'error_table': 'TotalMAE',
    'swa': True,                      # 随机权重平均
    'start_swa': 800,
    'ema': True,                      # 指数移动平均
    'ema_decay': 0.99,
    'lr': 0.001,                      # 学习率
    'patience': 50,
    'scheduler_patience': 20,
    'seed': 345,
    'amsgrad': True,
    'restart_latest': False,
    'save_cpu': True,
    'num_workers': 20,
    'max_L': 1,
    'dtype': 'float32',
    'cueq': False,
}
```

### MACE 设备配置

MACE 会自动检测 CUDA 是否可用：

```python
# 自动检测（默认）
# mlt.Config.mace_params['device'] 会自动设置为 'cuda' 或 'cpu'

# 手动设置
mlt.Config.mace_params['device'] = 'cuda'  # 使用 GPU
mlt.Config.mace_params['device'] = 'cpu'   # 使用 CPU
```

## 自定义配置示例

### 示例 1：高精度 GAP

```python
import mlptrain as mlt

# 设置更严格的噪声参数
mlt.Config.gap_default_params = {
    'sigma_E': 10**(-5.0),  # 更小的能量噪声
    'sigma_F': 10**(-3.0),  # 更小的力噪声
}

# 使用更大的 SOAP 描述符
mlt.Config.gap_default_soap_params = {
    'cutoff': 6.0,      # 更大的截断半径
    'n_sparse': 2000,   # 更多的稀疏点
    'l_max': 8,         # 更高的角动量
    'sigma_at': 0.3,    # 更小的原子宽度
}
```

### 示例 2：快速 MACE 训练

```python
import mlptrain as mlt

# 减少训练轮数
mlt.Config.mace_params['max_num_epochs'] = 600

# 增大批次大小（如果内存允许）
mlt.Config.mace_params['batch_size'] = 20

# 使用 GPU
mlt.Config.mace_params['device'] = 'cuda'
```

### 示例 3：多核并行

```python
import mlptrain as mlt

# 设置核心数
mlt.Config.n_cores = 20

# 确保 n_configs_iter 是 n_cores 的约数
gap.al_train(
    method_name='orca',
    temp=1000,
    n_configs_iter=10  # 20 是 10 的倍数，OK
)
```

## 配置验证

### 检查配置

```python
# 打印所有配置
print(mlt.Config.n_cores)
print(mlt.Config.orca_keywords)
print(mlt.Config.gap_default_params)
```

### 重置为默认值

```python
# 重新导入以重置（不推荐）
import importlib
importlib.reload(mlptrain.config)

# 或手动重置
mlt.Config.n_cores = 4
mlt.Config.orca_keywords = None
```

## 环境变量

某些配置可以通过环境变量设置：

```bash
# 设置 OMP 线程数
export OMP_NUM_THREADS=4

# 设置 CUDA 设备
export CUDA_VISIBLE_DEVICES=0
```

## 配置文件

虽然 mlp-train 不直接支持配置文件，但您可以在 Python 脚本中集中管理配置：

```python
# config.py
import mlptrain as mlt

# 项目特定配置
mlt.Config.n_cores = 16
mlt.Config.orca_keywords = ['PBE', 'def2-SVP', 'EnGrad']

# 自定义 MACE 参数
mlt.Config.mace_params.update({
    'max_num_epochs': 1500,
    'lr': 0.0005,
})

# 在主脚本中导入
# from config import *  # 应用配置
```

## 最佳实践

1. **在脚本开头设置配置**：
   ```python
   import mlptrain as mlt
   mlt.Config.n_cores = 10
   mlt.Config.orca_keywords = ['PBE', 'def2-SVP', 'EnGrad']
   ```

2. **根据系统调整参数**：
   - 小系统：可以使用更精确的参数
   - 大系统：可能需要更快的参数

3. **测试配置**：
   - 先用小规模测试验证配置
   - 再应用到大规模计算

4. **文档化配置**：
   - 在脚本中注释说明配置选择
   - 记录参数调整的原因

## 常见配置问题

### 问题 1：n_cores 与 n_configs_iter 不匹配

**错误**：
```
Active learning is only implemented using an multiple of the number n_configs_iter.
```

**解决方案**：
```python
# 确保 n_cores 是 n_configs_iter 的倍数
mlt.Config.n_cores = 10
gap.al_train(..., n_configs_iter=5)  # 10 是 5 的倍数，OK
```

### 问题 2：ORCA/Gaussian 未配置

**错误**：
```
ORCA keywords must be gradient
```

**解决方案**：
```python
mlt.Config.orca_keywords = ['PBE', 'def2-SVP', 'EnGrad']
# 或
mlt.Config.gaussian_keywords = ['PBEPBE', 'Def2SVP', 'Force(NoStep)']
```

### 问题 3：MACE CUDA 不可用

**解决方案**：
```python
# 检查 CUDA
import torch
print(torch.cuda.is_available())

# 如果不可用，使用 CPU
mlt.Config.mace_params['device'] = 'cpu'
```

## 下一步

- 查看 [API 参考](10_API参考.md) 了解详细 API
- 参考 [示例教程](09_示例教程.md) 查看实际应用
