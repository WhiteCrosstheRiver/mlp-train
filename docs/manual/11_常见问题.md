# 常见问题

本章节回答使用 mlp-train 时遇到的常见问题。

## 安装问题

### Q1: 安装 ACE 时提示找不到 Julia

**问题**：运行 `./install_ace.sh` 时出现 "Julia not found" 错误。

**解决方案**：
1. 确保已安装 Julia（版本 >= 1.6）
2. 检查 Julia 是否在 PATH 中：
   ```bash
   which julia
   ```
3. 如果未找到，将 Julia 添加到 PATH：
   ```bash
   export PATH=$PATH:/path/to/julia/bin
   ```

### Q2: MACE 安装时 CUDA 相关错误

**问题**：MACE 安装时出现 CUDA 版本不兼容错误。

**解决方案**：
1. 检查 CUDA 驱动版本：
   ```bash
   nvidia-smi
   ```
2. 使用 `CONDA_OVERRIDE_CUDA` 指定兼容版本：
   ```bash
   CONDA_OVERRIDE_CUDA="11.2" ./install_mace.sh
   ```
3. 如果不需要 GPU，可以安装 CPU 版本（默认）

### Q3: 权限错误

**问题**：无法执行安装脚本。

**解决方案**：
```bash
chmod +x install_*.sh
```

## 配置问题

### Q4: n_cores 与 n_configs_iter 不匹配

**错误信息**：
```
Active learning is only implemented using an multiple of the number n_configs_iter.
```

**原因**：`n_cores` 必须是 `n_configs_iter` 的倍数。

**解决方案**：
```python
# 确保 n_cores 是 n_configs_iter 的倍数
mlt.Config.n_cores = 10
gap.al_train(..., n_configs_iter=5)  # 10 是 5 的倍数，OK

# 或调整 n_configs_iter
mlt.Config.n_cores = 8
gap.al_train(..., n_configs_iter=4)  # 8 是 4 的倍数，OK
```

### Q5: ORCA/Gaussian 未配置

**错误信息**：
```
ORCA keywords must be gradient
```

**解决方案**：
```python
# 配置 ORCA
mlt.Config.orca_keywords = ['PBE', 'def2-SVP', 'EnGrad']

# 或配置 Gaussian
mlt.Config.gaussian_keywords = ['PBEPBE', 'Def2SVP', 'Force(NoStep)']
```

### Q6: MACE CUDA 不可用

**问题**：MACE 无法使用 GPU。

**解决方案**：
```python
# 检查 CUDA
import torch
print(torch.cuda.is_available())

# 如果不可用，使用 CPU
mlt.Config.mace_params['device'] = 'cpu'
```

## 训练问题

### Q7: 训练过程中没有添加新构型

**问题**：主动学习迭代多次，但训练数据集没有增长。

**可能原因**：
1. 选择方法阈值设置不当
2. MLP 已经足够准确
3. 温度过低，构型空间探索不足

**解决方案**：
1. 调整选择方法参数：
   ```python
   # 对于 AbsDiffE，降低阈值
   selector = AbsDiffE(e_thresh=0.05)  # 从 0.1 降低到 0.05
   
   # 对于 AtomicEnvSimilarity，调整阈值
   selector = AtomicEnvSimilarity(descriptor=desc, threshold=0.99)
   ```
2. 提高温度：
   ```python
   gap.al_train(method_name='orca', temp=1500)  # 从 1000 提高到 1500
   ```
3. 检查训练数据：
   ```python
   print(f"训练数据点数: {gap.n_train}")
   ```

### Q8: 训练时间过长

**问题**：主动学习训练需要很长时间。

**解决方案**：
1. 减少迭代次数和构型数：
   ```python
   gap.al_train(
       method_name='xtb',  # 使用更快的参考方法
       temp=1000,
       max_active_iters=10,  # 减少迭代次数
       n_configs_iter=5,     # 减少每次迭代的构型数
       max_active_time=500,  # 减少每次迭代的时间
   )
   ```
2. 使用更快的参考方法（xTB 而不是 ORCA）
3. 减少核心数（如果受内存限制）

### Q9: 内存不足

**问题**：训练过程中出现内存错误。

**解决方案**：
1. 减少并行核心数：
   ```python
   mlt.Config.n_cores = 4  # 从 10 减少到 4
   ```
2. 减少每次迭代的构型数：
   ```python
   gap.al_train(..., n_configs_iter=5)  # 从 10 减少到 5
   ```
3. 使用更小的系统进行测试

## MD 模拟问题

### Q10: 能量不守恒

**问题**：MD 模拟中能量不守恒。

**可能原因**：
1. 时间步长太大
2. MLP 预测不准确
3. 起始构型不合理

**解决方案**：
1. 减小时间步长：
   ```python
   trajectory = mlt.md.run_mlp_md(..., dt=0.25)  # 从 0.5 减小到 0.25
   ```
2. 重新训练 MLP，增加训练数据
3. 使用能量最小化后的构型作为起始点

### Q11: 模拟崩溃

**问题**：MD 模拟中途崩溃。

**可能原因**：
1. 起始构型不合理
2. 温度过高
3. MLP 在未训练区域预测

**解决方案**：
1. 使用能量最低的构型：
   ```python
   config = system.configuration  # 使用最低能量构型
   ```
2. 降低温度：
   ```python
   trajectory = mlt.md.run_mlp_md(..., temp=200)  # 从 300 降低到 200
   ```
3. 增加训练数据覆盖范围：
   ```python
   gap.al_train(..., temp=1500)  # 提高温度以探索更多区域
   ```

### Q12: OpenMM 无法找到 GPU

**问题**：OpenMM 无法使用 GPU。

**解决方案**：
```python
# 明确指定使用 CPU
trajectory = mlt.md_openmm.run_mlp_md_openmm(..., platform='CPU')

# 或检查可用平台
from openmm import Platform
print(Platform.getPlatformByName('CUDA').isAvailable())
```

## 高级采样问题

### Q13: 元动力学偏置增长过快

**问题**：元动力学偏置增长过快，导致采样受限。

**解决方案**：
1. 使用良好调温元动力学：
   ```python
   metad.bias_factor = 20.0  # 增加偏置因子
   ```
2. 减小高斯高度：
   ```python
   metad.height = 0.05  # 从 0.1 减小到 0.05
   ```
3. 增加添加高斯的频率：
   ```python
   metad.pace = 200  # 从 100 增加到 200
   ```

### Q14: 伞形采样窗口重叠不足

**问题**：伞形采样窗口之间重叠不足，导致自由能计算不准确。

**解决方案**：
1. 减小窗口间距：
   ```python
   windows = [1.5, 1.7, 1.9, 2.1, 2.3]  # 从 0.5 间距减小到 0.2
   ```
2. 增加弹簧常数：
   ```python
   kappas = [0.2] * len(windows)  # 从 0.1 增加到 0.2
   ```
3. 增加模拟时间：
   ```python
   umbrella.run(..., fs=10000)  # 从 5000 增加到 10000
   ```

## 性能问题

### Q15: 计算速度慢

**问题**：训练或模拟速度很慢。

**解决方案**：
1. 使用更快的参考方法（xTB 而不是 ORCA）
2. 减少训练数据量（用于测试）
3. 使用 GPU（MACE 模型）
4. 优化并行设置：
   ```python
   mlt.Config.n_cores = 16  # 根据系统调整
   ```

### Q16: 内存使用过高

**问题**：内存使用过高，可能导致系统崩溃。

**解决方案**：
1. 减少并行核心数
2. 减少批次大小（MACE）
3. 使用更小的系统进行测试
4. 定期清理不需要的数据

## 其他问题

### Q17: 如何查看训练进度？

**解决方案**：
训练过程中会输出日志信息，包括：
- 当前迭代次数
- 已添加的构型数
- 训练数据集大小
- 能量误差统计

您也可以检查训练数据：
```python
print(f"训练数据点数: {gap.n_train}")
```

### Q18: 如何保存和加载模型？

**解决方案**：
```python
# 保存（通常在训练时自动保存）
gap.save()

# 加载
gap.load()
```

### Q19: 如何比较不同模型？

**解决方案**：
```python
# 使用相同的测试轨迹
trajectory.compare(gap, 'orca')
trajectory.compare(ace, 'orca')
trajectory.compare(mace, 'orca')
```

### Q20: 如何联系开发者？

**解决方案**：
- **GitHub Issues**：https://github.com/duartegroup/mlp-train/issues
- 查看项目 README 获取更多信息

## 获取帮助

如果以上问题都无法解决您的问题：

1. 查看 [GitHub Issues](https://github.com/duartegroup/mlp-train/issues)
2. 阅读项目文档
3. 查看示例代码
4. 提交新的 Issue（包含错误信息和复现步骤）

## 下一步

- 查看 [最佳实践](12_最佳实践.md) 优化您的使用
- 参考 [示例教程](09_示例教程.md) 学习实际应用
